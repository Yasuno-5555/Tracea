warning: tracea@0.1.0: CUDA (nvcc) not found. Skipping template compilation.
    Checking tracea v0.1.0 (E:\Projects\Tracea)
warning: unused import: `crate::backend::cuda::CudaBackend`
 --> src\kernels\attention\cuda_emitter.rs:2:5
  |
2 | use crate::backend::cuda::CudaBackend;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  |
  = note: `#[warn(unused_imports)]` (part of `#[warn(unused)]`) on by default

warning: unused import: `ParameterRange`
 --> src\kernels\attention\cuda_adapter.rs:1:55
  |
1 | use crate::core::tuning::{TunableKernel, SearchSpace, ParameterRange};
  |                                                       ^^^^^^^^^^^^^^

warning: unused import: `QuantizationMode`
 --> src\kernels\attention\cuda_adapter.rs:2:80
  |
2 | use crate::core::config::{PipelineConfig, SwizzleMode, SpecializedInstruction, QuantizationMode};
  |                                                                                ^^^^^^^^^^^^^^^^

warning: unused import: `SpecializedInstruction`
 --> src\kernels\attention\rocm_adapter.rs:2:56
  |
2 | use crate::core::config::{PipelineConfig, SwizzleMode, SpecializedInstruction};
  |                                                        ^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::emitter::rocm::ROCMEmitter`
 --> src\kernels\attention\rocm_adapter.rs:3:5
  |
3 | use crate::emitter::rocm::ROCMEmitter;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `KernelArg`
 --> src\kernels\attention\rocm_adapter.rs:4:62
  |
4 | use crate::runtime::manager::{RuntimeManager, DeviceBackend, KernelArg};
  |                                                              ^^^^^^^^^

warning: unused imports: `SpecializedInstruction` and `SwizzleMode`
 --> src\kernels\attention\metal_adapter.rs:2:43
  |
2 | use crate::core::config::{PipelineConfig, SwizzleMode, SpecializedInstruction};
  |                                           ^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::emitter::metal::MetalEmitter`
 --> src\kernels\attention\metal_adapter.rs:3:5
  |
3 | use crate::emitter::metal::MetalEmitter;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `KernelArg`
 --> src\kernels\attention\metal_adapter.rs:4:62
  |
4 | use crate::runtime::manager::{RuntimeManager, DeviceBackend, KernelArg};
  |                                                              ^^^^^^^^^

warning: unused import: `wide::*`
 --> src\kernels\cpu\gemm.rs:2:5
  |
2 | use wide::*;
  |     ^^^^^^^

warning: unused import: `std::convert::TryInto`
 --> src\kernels\cpu\gemm.rs:3:5
  |
3 | use std::convert::TryInto;
  |     ^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `DeviceBackend` and `KernelArg`
 --> src\kernels\gpu\gpu_dispatch.rs:2:31
  |
2 | use crate::runtime::manager::{DeviceBackend, KernelArg};
  |                               ^^^^^^^^^^^^^  ^^^^^^^^^

warning: unused import: `std::collections::HashSet`
 --> src\semantic\mapping.rs:1:5
  |
1 | use std::collections::HashSet;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `UnifiedOpIR` and `UnifiedOpType`
 --> src\emitter\jit.rs:4:39
  |
4 | use crate::emitter::traits::{Emitter, UnifiedOpIR, UnifiedOpType};
  |                                       ^^^^^^^^^^^  ^^^^^^^^^^^^^

warning: unused import: `LayoutPolicy`
 --> src\emitter\cuda.rs:3:43
  |
3 | use crate::core::config::{PipelineConfig, LayoutPolicy};
  |                                           ^^^^^^^^^^^^

warning: unused import: `Ptx`
 --> src\runtime\manager.rs:5:37
  |
5 | use cudarc::nvrtc::{CompileOptions, Ptx};
  |                                     ^^^

warning: unused import: `CString`
 --> src\runtime\manager.rs:6:24
  |
6 | use std::ffi::{c_void, CString};
  |                        ^^^^^^^

warning: unused imports: `AssemblerResultInfo`, `BackendKind`, `JitResultInfo`, `KernelLaunchInfo`, and `ModuleLoadInfo`
  --> src\runtime\manager.rs:11:21
   |
11 | use crate::doctor::{BackendKind, JitResultInfo, AssemblerResultInfo, KernelLaunchInfo, ModuleLoadInfo};
   |                     ^^^^^^^^^^^  ^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^

warning: unused import: `cudarc::driver::CudaDevice`
 --> src\optimizer\mod.rs:3:5
  |
3 | use cudarc::driver::CudaDevice;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `Node`
 --> src\optimizer\semantic.rs:1:33
  |
1 | use crate::core::graph::{Graph, Node, Operation};
  |                                 ^^^^

warning: unused imports: `EpilogueOp` and `FusedGemmOp`
 --> src\optimizer\semantic.rs:2:23
  |
2 | use crate::core::op::{FusedGemmOp, EpilogueOp};
  |                       ^^^^^^^^^^^  ^^^^^^^^^^

warning: unused import: `Conv2dProblem`
   --> src\optimizer\mod.rs:218:92
    |
218 | use benchmark::{MicroBenchmark, Observation, BenchmarkResult, Conv2dBenchmark, ConvConfig, Conv2dProblem};
    |                                                                                            ^^^^^^^^^^^^^

warning: unused imports: `Deserialize` and `Serialize`
 --> src\doctor\mod.rs:1:13
  |
1 | use serde::{Serialize, Deserialize};
  |             ^^^^^^^^^  ^^^^^^^^^^^

warning: unused import: `Path`
 --> src\doctor\diagnosis.rs:1:17
  |
1 | use std::path::{Path, PathBuf};
  |                 ^^^^

error[E0609]: no field `hipModuleUnload` on type `&rocm_driver::RocmDriverApi`
   --> src\runtime\manager.rs:107:31
    |
107 |                 unsafe { (api.hipModuleUnload)(self.0); }
    |                               ^^^^^^^^^^^^^^^ unknown field
    |
    = note: available fields are: `lib`, `hipGetDeviceCount`, `hipDeviceGetAttribute`, `hipGetDeviceProperties`, `hipMalloc` ... and 7 others

warning: unused import: `DiagnosticStrategy`
 --> src\doctor\diagnosis.rs:9:47
  |
9 | use crate::doctor::strategies::{get_strategy, DiagnosticStrategy};
  |                                               ^^^^^^^^^^^^^^^^^^

warning: unused variable: `d_over_16`
  --> src\kernels\attention\cuda_emitter.rs:45:13
   |
45 |         let d_over_16 = d / 16;
   |             ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_d_over_16`
   |
   = note: `#[warn(unused_variables)]` (part of `#[warn(unused)]`) on by default

warning: unused variable: `cfg`
  --> src\kernels\attention\rocm_adapter.rs:72:25
   |
72 |     fn benchmark(&self, cfg: &Self::Config) -> Option<f32> {
   |                         ^^^ help: if this is intentional, prefix it with an underscore: `_cfg`

warning: unused variable: `bytes`
  --> src\kernels\attention\metal_adapter.rs:29:13
   |
29 |         let bytes = problem.b * problem.h * problem.s * problem.d * 2;
   |             ^^^^^ help: if this is intentional, prefix it with an underscore: `_bytes`

warning: unused variable: `a_ptr`
   --> src\kernels\gemm\cuda_gemm.rs:121:13
    |
121 |         let a_ptr = self.runtime.get_device_ptr(self.a_buf).ok()?;
    |             ^^^^^ help: if this is intentional, prefix it with an underscore: `_a_ptr`

warning: unused variable: `b_ptr`
   --> src\kernels\gemm\cuda_gemm.rs:122:13
    |
122 |         let b_ptr = self.runtime.get_device_ptr(self.b_buf).ok()?;
    |             ^^^^^ help: if this is intentional, prefix it with an underscore: `_b_ptr`

warning: unused variable: `c_ptr`
   --> src\kernels\gemm\cuda_gemm.rs:123:13
    |
123 |         let c_ptr = self.runtime.get_device_ptr(self.c_buf).ok()?;
    |             ^^^^^ help: if this is intentional, prefix it with an underscore: `_c_ptr`

warning: unused variable: `block_threads`
   --> src\kernels\gemm\metal_gemm.rs:121:13
    |
121 |         let block_threads = 128;
    |             ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_block_threads`

warning: variable does not need to be mutable
  --> src\kernels\gemm\cpu_adapter.rs:63:21
   |
63 |                 let mut cfg = CpuGemmConfig {
   |                     ----^^^
   |                     |
   |                     help: remove this `mut`
   |
   = note: `#[warn(unused_mut)]` (part of `#[warn(unused)]`) on by default

error[E0507]: cannot move out of `*b` which is behind a shared reference
   --> src\core\graph.rs:215:60
    |
215 |                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
    |                                                            ^^ move occurs because `*b` has type `DimExpr`, which does not implement the `Copy` trait
    |
help: consider cloning the value if the performance cost is acceptable
    |
215 -                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
215 +                 let new_id = optimized.add_fused_attention(b.clone(), *s, *d, *h, *dh, *causal, deps);
    |

error[E0507]: cannot move out of `*s` which is behind a shared reference
   --> src\core\graph.rs:215:64
    |
215 |                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
    |                                                                ^^ move occurs because `*s` has type `DimExpr`, which does not implement the `Copy` trait
    |
help: consider cloning the value if the performance cost is acceptable
    |
215 -                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
215 +                 let new_id = optimized.add_fused_attention(*b, s.clone(), *d, *h, *dh, *causal, deps);
    |

error[E0507]: cannot move out of `*d` which is behind a shared reference
   --> src\core\graph.rs:215:68
    |
215 |                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
    |                                                                    ^^ move occurs because `*d` has type `DimExpr`, which does not implement the `Copy` trait
    |
help: consider cloning the value if the performance cost is acceptable
    |
215 -                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
215 +                 let new_id = optimized.add_fused_attention(*b, *s, d.clone(), *h, *dh, *causal, deps);
    |

error[E0507]: cannot move out of `*h` which is behind a shared reference
   --> src\core\graph.rs:215:72
    |
215 |                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
    |                                                                        ^^ move occurs because `*h` has type `DimExpr`, which does not implement the `Copy` trait
    |
help: consider cloning the value if the performance cost is acceptable
    |
215 -                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
215 +                 let new_id = optimized.add_fused_attention(*b, *s, *d, h.clone(), *dh, *causal, deps);
    |

error[E0507]: cannot move out of `*dh` which is behind a shared reference
   --> src\core\graph.rs:215:76
    |
215 |                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
    |                                                                            ^^^ move occurs because `*dh` has type `DimExpr`, which does not implement the `Copy` trait
    |
help: consider cloning the value if the performance cost is acceptable
    |
215 -                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, *dh, *causal, deps);
215 +                 let new_id = optimized.add_fused_attention(*b, *s, *d, *h, dh.clone(), *causal, deps);
    |

warning: unused variable: `row`
  --> src\semantic\mapping.rs:20:28
   |
20 |     pub fn get_addr(&self, row: u32, col: u32) -> String {
   |                            ^^^ help: if this is intentional, prefix it with an underscore: `_row`

warning: unused variable: `col`
  --> src\semantic\mapping.rs:20:38
   |
20 |     pub fn get_addr(&self, row: u32, col: u32) -> String {
   |                                      ^^^ help: if this is intentional, prefix it with an underscore: `_col`

warning: unused variable: `b_smem_offset`
  --> src\emitter\cuda.rs:36:13
   |
36 |         let b_smem_offset = (a_smem_offset + smem_a_bytes * stages as u32 + 1023) & !1023;
   |             ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_b_smem_offset`

warning: unused variable: `m`
   --> src\emitter\cuda.rs:368:41
    |
368 |             UnifiedOpType::MatrixCore { m, n, k } => {
    |                                         ^ help: try ignoring the field: `m: _`

warning: unused variable: `n`
   --> src\emitter\cuda.rs:368:44
    |
368 |             UnifiedOpType::MatrixCore { m, n, k } => {
    |                                            ^ help: try ignoring the field: `n: _`

warning: unused variable: `k`
   --> src\emitter\cuda.rs:368:47
    |
368 |             UnifiedOpType::MatrixCore { m, n, k } => {
    |                                               ^ help: try ignoring the field: `k: _`

warning: unused variable: `k_out`
  --> src\emitter\metal.rs:98:76
   |
98 |     if let UnifiedOpType::Conv2d { n: batch, h: h_in, w: w_in, c: c_in, k: k_out, r, s, stride, pad, dilation, .. } = ir.op_type {
   |                                                                            ^^^^^ help: if this is intentional, prefix it with an underscore: `_k_out`

warning: unused variable: `k_gemm`
   --> src\emitter\metal.rs:103:13
    |
103 |         let k_gemm = c_in * r * s;
    |             ^^^^^^ help: if this is intentional, prefix it with an underscore: `_k_gemm`

warning: unused variable: `n`
 --> src\emitter\elementwise.rs:5:19
  |
5 |     let (op_type, n) = match &ir.op_type {
  |                   ^ help: if this is intentional, prefix it with an underscore: `_n`

warning: unused variable: `n_gemm`
  --> src\emitter\conv.rs:25:13
   |
25 |         let n_gemm = k_out;
   |             ^^^^^^ help: if this is intentional, prefix it with an underscore: `_n_gemm`

warning: unused variable: `hw_magic`
  --> src\emitter\conv.rs:45:14
   |
45 |         let (hw_magic, hw_shift) = magic_u32((h_out * w_out) as u32);
   |              ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_hw_magic`

warning: unused variable: `hw_shift`
  --> src\emitter\conv.rs:45:24
   |
45 |         let (hw_magic, hw_shift) = magic_u32((h_out * w_out) as u32);
   |                        ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_hw_shift`

warning: unused variable: `w_magic`
  --> src\emitter\conv.rs:46:14
   |
46 |         let (w_magic, w_shift) = magic_u32(w_out as u32);
   |              ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_w_magic`

warning: unused variable: `w_shift`
  --> src\emitter\conv.rs:46:23
   |
46 |         let (w_magic, w_shift) = magic_u32(w_out as u32);
   |                       ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_w_shift`

warning: unused variable: `sic_magic`
  --> src\emitter\conv.rs:47:14
   |
47 |         let (sic_magic, sic_shift) = magic_u32((s * c_in) as u32);
   |              ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_sic_magic`

warning: unused variable: `sic_shift`
  --> src\emitter\conv.rs:47:25
   |
47 |         let (sic_magic, sic_shift) = magic_u32((s * c_in) as u32);
   |                         ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_sic_shift`

warning: unused variable: `c_magic`
  --> src\emitter\conv.rs:48:14
   |
48 |         let (c_magic, c_shift) = magic_u32(c_in as u32);
   |              ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_c_magic`

warning: unused variable: `c_shift`
  --> src\emitter\conv.rs:48:23
   |
48 |         let (c_magic, c_shift) = magic_u32(c_in as u32);
   |                       ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_c_shift`

warning: unused variable: `use_ampere`
  --> src\emitter\conv.rs:54:13
   |
54 |         let use_ampere = (c_in % 8 == 0) && (k_out % 8 == 0);
   |             ^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_use_ampere`

warning: unused variable: `m`
 --> src\emitter\gemm.rs:5:34
  |
5 |     if let UnifiedOpType::Gemm { m, n, k } = ir.op_type {
  |                                  ^ help: try ignoring the field: `m: _`

warning: unused variable: `n`
 --> src\emitter\gemm.rs:5:37
  |
5 |     if let UnifiedOpType::Gemm { m, n, k } = ir.op_type {
  |                                     ^ help: try ignoring the field: `n: _`

warning: unused variable: `k`
 --> src\emitter\gemm.rs:5:40
  |
5 |     if let UnifiedOpType::Gemm { m, n, k } = ir.op_type {
  |                                        ^ help: try ignoring the field: `k: _`

warning: unused variable: `b`
 --> src\emitter\attention.rs:5:44
  |
5 |     if let UnifiedOpType::FusedAttention { b, s, d, h, dh, causal } = ir.op_type {
  |                                            ^ help: try ignoring the field: `b: _`

warning: unused variable: `s`
 --> src\emitter\attention.rs:5:47
  |
5 |     if let UnifiedOpType::FusedAttention { b, s, d, h, dh, causal } = ir.op_type {
  |                                               ^ help: try ignoring the field: `s: _`

warning: unused variable: `d`
 --> src\emitter\attention.rs:5:50
  |
5 |     if let UnifiedOpType::FusedAttention { b, s, d, h, dh, causal } = ir.op_type {
  |                                                  ^ help: try ignoring the field: `d: _`

warning: unused variable: `h`
 --> src\emitter\attention.rs:5:53
  |
5 |     if let UnifiedOpType::FusedAttention { b, s, d, h, dh, causal } = ir.op_type {
  |                                                     ^ help: try ignoring the field: `h: _`

warning: unused variable: `dh`
 --> src\emitter\attention.rs:5:56
  |
5 |     if let UnifiedOpType::FusedAttention { b, s, d, h, dh, causal } = ir.op_type {
  |                                                        ^^ help: try ignoring the field: `dh: _`

warning: unused variable: `causal`
 --> src\emitter\attention.rs:5:60
  |
5 |     if let UnifiedOpType::FusedAttention { b, s, d, h, dh, causal } = ir.op_type {
  |                                                            ^^^^^^ help: try ignoring the field: `causal: _`

warning: unused variable: `pref_backend`
   --> src\runtime\manager.rs:213:17
    |
213 |     pub fn init(pref_backend: Option<DeviceBackend>) -> Result<Arc<Self>, String> {
    |                 ^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_pref_backend`

warning: variable does not need to be mutable
   --> src\runtime\manager.rs:338:21
    |
338 |                 let mut opts = CompileOptions {
    |                     ----^^^^
    |                     |
    |                     help: remove this `mut`

warning: unused variable: `res_attr`
   --> src\runtime\manager.rs:407:25
    |
407 |                     let res_attr = lib.cuFuncSetAttribute(
    |                         ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_res_attr`

warning: unreachable pattern
   --> src\runtime\manager.rs:577:13
    |
577 |             _ => return Err("Unsupported backend".to_string()),
    |             ^ no value can reach this
    |
note: multiple earlier patterns match some of the same values
   --> src\runtime\manager.rs:577:13
    |
497 |             KernelHandle::Cuda { func, .. } => {
    |             ------------------------------- matches some of the same values
...
534 |             KernelHandle::Rocm { func, .. } => {
    |             ------------------------------- matches some of the same values
...
577 |             _ => return Err("Unsupported backend".to_string()),
    |             ^ collectively making this unreachable
    = note: `#[warn(unreachable_patterns)]` (part of `#[warn(unused)]`) on by default

warning: unused variable: `nt`
   --> src\optimizer\benchmark.rs:911:13
    |
911 |         let nt = config.n_tile as usize; 
    |             ^^ help: if this is intentional, prefix it with an underscore: `_nt`

warning: unreachable pattern
   --> src\optimizer\policy.rs:175:13
    |
175 |             _ => {}
    |             ^ no value can reach this
    |
note: multiple earlier patterns match some of the same values
   --> src\optimizer\policy.rs:175:13
    |
138 |             Layout::NHWC => {
    |             ------------ matches some of the same values
...
163 |             Layout::NCHW => {
    |             ------------ matches some of the same values
...
175 |             _ => {}
    |             ^ collectively making this unreachable

warning: unused variable: `ctx`
   --> src\optimizer\policy.rs:207:29
    |
207 |     fn sampling_plan(&self, ctx: &TuningContext) -> SamplingPlan {
    |                             ^^^ help: if this is intentional, prefix it with an underscore: `_ctx`

warning: unused variable: `ctx`
   --> src\optimizer\policy.rs:293:29
    |
293 |     fn sampling_plan(&self, ctx: &TuningContext) -> SamplingPlan {
    |                             ^^^ help: if this is intentional, prefix it with an underscore: `_ctx`

warning: unused variable: `ctx`
   --> src\optimizer\policy.rs:406:29
    |
406 |     fn sampling_plan(&self, ctx: &TuningContext) -> SamplingPlan {
    |                             ^^^ help: if this is intentional, prefix it with an underscore: `_ctx`

warning: unused variable: `graph`
  --> src\optimizer\semantic.rs:12:26
   |
12 |     fn fuse_nodes(&self, graph: &mut Graph) {
   |                          ^^^^^ help: if this is intentional, prefix it with an underscore: `_graph`

warning: unused variable: `n`
  --> src\optimizer\semantic.rs:24:43
   |
24 |                     if let (Some(m), Some(n), Some(k)) = (gemm.m.as_static(), gemm.n.as_static(), gemm.k.as_static()) {
   |                                           ^ help: if this is intentional, prefix it with an underscore: `_n`

warning: unused variable: `k`
  --> src\optimizer\semantic.rs:24:52
   |
24 |                     if let (Some(m), Some(n), Some(k)) = (gemm.m.as_static(), gemm.n.as_static(), gemm.k.as_static()) {
   |                                                    ^ help: if this is intentional, prefix it with an underscore: `_k`

warning: unused variable: `init`
   --> src\optimizer\mod.rs:605:18
    |
605 |              let init = PipelineConfig::new(2, 128, 128, 32); 
    |                  ^^^^ help: if this is intentional, prefix it with an underscore: `_init`

warning: unreachable pattern
   --> src\doctor\engine.rs:180:17
    |
179 |                 BackendKind::Vulkan => CompileStrategy::JIT,
    |                 ------------------- matches all the relevant values
180 |                 BackendKind::Vulkan => CompileStrategy::JIT,
    |                 ^^^^^^^^^^^^^^^^^^^ no value can reach this

warning: variable does not need to be mutable
  --> src\doctor\visualizer.rs:23:13
   |
23 |         let mut data1 = vec![0.0f32; size];
   |             ----^^^^^
   |             |
   |             help: remove this `mut`

warning: variable does not need to be mutable
  --> src\doctor\visualizer.rs:24:13
   |
24 |         let mut data2 = vec![0.0f32; size];
   |             ----^^^^^
   |             |
   |             help: remove this `mut`

warning: unused variable: `data1`
  --> src\doctor\visualizer.rs:23:13
   |
23 |         let mut data1 = vec![0.0f32; size];
   |             ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_data1`

warning: unused variable: `data2`
  --> src\doctor\visualizer.rs:24:13
   |
24 |         let mut data2 = vec![0.0f32; size];
   |             ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_data2`

warning: unused variable: `mse`
  --> src\doctor\visualizer.rs:65:40
   |
65 |     fn analyze_causes(&self, mae: f32, mse: f32) -> String {
   |                                        ^^^ help: if this is intentional, prefix it with an underscore: `_mse`

Some errors have detailed explanations: E0507, E0609.
For more information about an error, try `rustc --explain E0507`.
warning: `tracea` (lib) generated 80 warnings
warning: tracea@0.1.0: CUDA (nvcc) not found. Skipping template compilation.
error: could not compile `tracea` (lib) due to 6 previous errors; 80 warnings emitted
