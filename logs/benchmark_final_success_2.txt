Tracea JIT: Device Compute Capability: 86
Tracea JIT: Compiling gemm_pipelined_kernel...
Tracea JIT: Generated PTX Version: .version 9.1
Tracea JIT: Patching PTX version 9.x -> 7.8 for compatibility
Tracea JIT: Successfully compiled and loaded gemm_pipelined_kernel
Tracea JIT: Probing handle for CudaFunction at 0x8dbd7eecb0
Tracea JIT: Found valid handle 0x239f0cdc720 at offset 8 (MaxThreads: 512)
Tracea JIT: Successfully set MaxDynamicSharedMemory to 99000 bytes
Tracea JIT: Probing handle for CudaFunction at 0x8dbd7eecb0
Tracea JIT: Found valid handle 0x239f0cdc720 at offset 8 (MaxThreads: 512)
Tracea JIT: Successfully set MaxDynamicSharedMemory to 99000 bytes
Tracea JIT: Compiling gemm_pipelined_kernel...
Tracea JIT: Generated PTX Version: .version 9.1
Tracea JIT: Patching PTX version 9.x -> 7.8 for compatibility
Tracea JIT: Successfully compiled and loaded gemm_pipelined_kernel
Tracea JIT: Probing handle for CudaFunction at 0x8dbd7eecb0
Tracea JIT: Found valid handle 0x239f0cdf740 at offset 8 (MaxThreads: 512)
Tracea JIT: Successfully set MaxDynamicSharedMemory to 99000 bytes
[Tracea] Benchmark Suite: Initializing for A100...
[WARN] CUDA not detected in PyTorch. Running in simulation/verification mode.

--- Phase A: Peak GEMM (Performance Verification) ---
Running 4096x4096x4096 GEMM...
Size 4096x4096: 197.838 ms (0.69 TFLOPS)
Running 8192x8192x8192 GEMM...
Size 8192x8192: 0.081 ms (13574.22 TFLOPS)

--- Phase B: Fusion Showdown (Transformer MLP Pattern) ---
Running Fused 4096x4096 ...
Fused Execution Time: 536.975 ms

[Tracea] Final Tracea Mastery Report
   Size      Op Backend        TFLOPS
0  4096  Matmul  Tracea      0.694705
1  8192  Matmul  Tracea  13574.217909
